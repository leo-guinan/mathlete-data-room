{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1761115656009744644"
        ],
        "editableUntil": "2024-02-23T20:47:46.000Z",
        "editsRemaining": "5",
        "isEditEligible": false
      }
    },
    "retweeted": false,
    "source": "<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [
        {
          "name": "anton ðŸ‡ºðŸ‡¸",
          "screen_name": "atroyn",
          "indices": [
            "0",
            "7"
          ],
          "id_str": "889394994607529984",
          "id": "889394994607529984"
        }
      ],
      "urls": []
    },
    "display_text_range": [
      "0",
      "246"
    ],
    "favorite_count": "0",
    "in_reply_to_status_id_str": "1761114312553422936",
    "id_str": "1761115656009744644",
    "in_reply_to_user_id": "889394994607529984",
    "truncated": false,
    "retweet_count": "0",
    "id": "1761115656009744644",
    "in_reply_to_status_id": "1761114312553422936",
    "created_at": "Fri Feb 23 19:47:46 +0000 2024",
    "favorited": false,
    "full_text": "@atroyn Alignment should never happen in the model. That makes no sense when you understand what alignment actually is and how we do it as humans. \n\nAlignment has to be external to a system, not internal. It can only exist in a containing system.",
    "lang": "en",
    "in_reply_to_screen_name": "atroyn",
    "in_reply_to_user_id_str": "889394994607529984"
  }
}