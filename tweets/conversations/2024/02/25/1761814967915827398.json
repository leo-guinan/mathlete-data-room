{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1761814967915827398"
        ],
        "editableUntil": "2024-02-25T19:06:35.000Z",
        "editsRemaining": "5",
        "isEditEligible": false
      }
    },
    "retweeted": false,
    "source": "<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [
        {
          "name": "AGIHound",
          "screen_name": "TrueAIHound",
          "indices": [
            "0",
            "12"
          ],
          "id_str": "957814045280690176",
          "id": "957814045280690176"
        },
        {
          "name": "Gary Marcus",
          "screen_name": "GaryMarcus",
          "indices": [
            "13",
            "24"
          ],
          "id_str": "232294292",
          "id": "232294292"
        }
      ],
      "urls": []
    },
    "display_text_range": [
      "0",
      "287"
    ],
    "favorite_count": "0",
    "in_reply_to_status_id_str": "1761808437594440184",
    "id_str": "1761814967915827398",
    "in_reply_to_user_id": "957814045280690176",
    "truncated": false,
    "retweet_count": "0",
    "id": "1761814967915827398",
    "in_reply_to_status_id": "1761808437594440184",
    "created_at": "Sun Feb 25 18:06:35 +0000 2024",
    "favorited": false,
    "full_text": "@TrueAIHound @GaryMarcus Well, I'd argue LLMs don't actually \"know\" anything. They also have no need to. They should be used as part of systems that define the scope of \"truth\" needed.\n\nI personally view LLMs as a way to translate data between deterministic and non-deterministic systems",
    "lang": "en",
    "in_reply_to_screen_name": "TrueAIHound",
    "in_reply_to_user_id_str": "957814045280690176"
  }
}