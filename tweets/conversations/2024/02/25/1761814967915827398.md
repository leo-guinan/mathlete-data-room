---
created_at: "Sun Feb 25 18:06:35 +0000 2024"
mentions: ['TrueAIHound', 'GaryMarcus']
in_reply_to: @TrueAIHound
---

@TrueAIHound @GaryMarcus Well, I'd argue LLMs don't actually "know" anything. They also have no need to. They should be used as part of systems that define the scope of "truth" needed.

I personally view LLMs as a way to translate data between deterministic and non-deterministic systems