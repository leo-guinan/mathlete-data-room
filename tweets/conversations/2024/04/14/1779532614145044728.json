{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1779532614145044728"
        ],
        "editableUntil": "2024-04-14T16:30:11.000Z",
        "editsRemaining": "5",
        "isEditEligible": false
      }
    },
    "retweeted": false,
    "source": "<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [
        {
          "name": "@SIL",
          "screen_name": "UrDeliveryMan1",
          "indices": [
            "0",
            "15"
          ],
          "id_str": "2207374660",
          "id": "2207374660"
        }
      ],
      "urls": []
    },
    "display_text_range": [
      "0",
      "292"
    ],
    "favorite_count": "1",
    "in_reply_to_status_id_str": "1779432795288359234",
    "id_str": "1779532614145044728",
    "in_reply_to_user_id": "2207374660",
    "truncated": false,
    "retweet_count": "0",
    "id": "1779532614145044728",
    "in_reply_to_status_id": "1779432795288359234",
    "created_at": "Sun Apr 14 15:30:11 +0000 2024",
    "favorited": false,
    "full_text": "@UrDeliveryMan1 It's been really cool to experiment with. Basically, my hypothesis is that I can get the submind to fully align with the user by learning about them and their values, which will then allow it to make decisions in the work to do or the quality of outcomes that will be similar.",
    "lang": "en",
    "in_reply_to_screen_name": "UrDeliveryMan1",
    "in_reply_to_user_id_str": "2207374660"
  }
}