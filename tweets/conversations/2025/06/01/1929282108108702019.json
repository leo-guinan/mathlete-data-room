{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1929282108108702019"
        ],
        "editableUntil": "2025-06-01T22:01:13.000Z",
        "editsRemaining": "5",
        "isEditEligible": false
      }
    },
    "retweeted": false,
    "source": "<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [
        {
          "name": "Jake Colling",
          "screen_name": "JacobColling",
          "indices": [
            "0",
            "13"
          ],
          "id_str": "1852630171",
          "id": "1852630171"
        },
        {
          "name": "clem ðŸ¤—",
          "screen_name": "ClementDelangue",
          "indices": [
            "14",
            "30"
          ],
          "id_str": "186420551",
          "id": "186420551"
        }
      ],
      "urls": []
    },
    "display_text_range": [
      "0",
      "309"
    ],
    "favorite_count": "1",
    "in_reply_to_status_id_str": "1929281720399908920",
    "id_str": "1929282108108702019",
    "in_reply_to_user_id": "1325102346792218629",
    "truncated": false,
    "retweet_count": "0",
    "id": "1929282108108702019",
    "in_reply_to_status_id": "1929281720399908920",
    "created_at": "Sun Jun 01 21:01:13 +0000 2025",
    "favorited": false,
    "full_text": "@JacobColling @ClementDelangue you can imagine a large model as a giant corpus of knowledge, but very little understanding of a specific context. The more the large model knows, the more fine-grained the context locally becomes. \n\nYou've got to model a system that understands the context and can work with it",
    "lang": "en",
    "in_reply_to_screen_name": "leo_guinan",
    "in_reply_to_user_id_str": "1325102346792218629"
  }
}