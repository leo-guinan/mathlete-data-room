{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1944780012550238699"
        ],
        "editableUntil": "2025-07-14T16:24:21.000Z",
        "editsRemaining": "5",
        "isEditEligible": false
      }
    },
    "retweeted": false,
    "source": "<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [
        {
          "name": "Alignment Lab AI",
          "screen_name": "alignment_lab",
          "indices": [
            "0",
            "14"
          ],
          "id_str": "1646494071731671043",
          "id": "1646494071731671043"
        },
        {
          "name": "Séb Krier",
          "screen_name": "sebkrier",
          "indices": [
            "15",
            "24"
          ],
          "id_str": "2228640597",
          "id": "2228640597"
        }
      ],
      "urls": []
    },
    "display_text_range": [
      "0",
      "297"
    ],
    "favorite_count": "1",
    "in_reply_to_status_id_str": "1944778985151332705",
    "id_str": "1944780012550238699",
    "in_reply_to_user_id": "1646494071731671043",
    "truncated": false,
    "retweet_count": "0",
    "id": "1944780012550238699",
    "in_reply_to_status_id": "1944778985151332705",
    "created_at": "Mon Jul 14 15:24:21 +0000 2025",
    "favorited": false,
    "full_text": "@alignment_lab @sebkrier I’m with you. \n\nI’d actually go so far as to say we don’t need larger LLMs at all and are actually starting to go backwards in terms of trying to hit every possible use case because we’ve got more than enough power to solve things at the edge, which is the most efficient.",
    "lang": "en",
    "in_reply_to_screen_name": "alignment_lab",
    "in_reply_to_user_id_str": "1646494071731671043"
  }
}