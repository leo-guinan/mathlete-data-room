{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1813005026937479435"
        ],
        "editableUntil": "2024-07-16T01:17:37.000Z",
        "editsRemaining": "5",
        "isEditEligible": true
      }
    },
    "retweeted": false,
    "source": "<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [],
      "urls": []
    },
    "display_text_range": [
      "0",
      "263"
    ],
    "favorite_count": "2",
    "id_str": "1813005026937479435",
    "truncated": false,
    "retweet_count": "0",
    "id": "1813005026937479435",
    "created_at": "Tue Jul 16 00:17:37 +0000 2024",
    "favorited": false,
    "full_text": "My new approach to webscraping, after I ended up running up a $300 OpenAI bill the other day on a scraper gone wrong:\n\nI now scrape the page and save it to a file before running it through LLMs. That way, I can make sure I know how many pages I have to process...",
    "lang": "en"
  }
}