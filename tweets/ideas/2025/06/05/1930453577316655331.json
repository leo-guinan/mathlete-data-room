{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1930453577316655331"
        ],
        "editableUntil": "2025-06-05T03:36:13.000Z",
        "editsRemaining": "5",
        "isEditEligible": false
      }
    },
    "retweeted": false,
    "source": "<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [],
      "urls": [
        {
          "url": "https://t.co/UuNK57cHXD",
          "expanded_url": "https://x.com/balajis/status/1930156049065246851",
          "display_url": "x.com/balajis/status‚Ä¶",
          "indices": [
            "155",
            "178"
          ]
        }
      ]
    },
    "display_text_range": [
      "0",
      "178"
    ],
    "favorite_count": "0",
    "id_str": "1930453577316655331",
    "truncated": false,
    "retweet_count": "0",
    "id": "1930453577316655331",
    "possibly_sensitive": false,
    "created_at": "Thu Jun 05 02:36:13 +0000 2025",
    "favorited": false,
    "full_text": "Balaji nails the ‚Äúverification gap‚Äù: gen ‚âà instant, verify = human-slow. Once LLMs vaporize creation time, the real latency shifts to checking the work. üßµ https://t.co/UuNK57cHXD",
    "lang": "en"
  }
}