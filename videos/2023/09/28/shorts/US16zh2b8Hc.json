{
  "id": "US16zh2b8Hc",
  "channel_id": "UC_Mn3zTIipnTQ8Zy_QtXZew",
  "title": "AI Dangers #shorts #ai",
  "description": "Full Videos: https://www.youtube.com/@listentoleonow?sub_confirmation=1\n\n#shorts #ai",
  "published_at": "2023-09-28T18:00:14+00:00",
  "view_count": 384,
  "like_count": 6,
  "comment_count": 0,
  "duration": "PT0M37S",
  "tags": [
    "shorts",
    "#shorts",
    "ai",
    "reacts"
  ],
  "transcript": "Kind: captions Language: en danger<00:00:01.020><c> of</c><00:00:01.199><c> AI</c><00:00:01.500><c> is</c><00:00:01.740><c> much</c><00:00:02.100><c> greater</c><00:00:02.460><c> than</c><00:00:02.760><c> the</c> danger of AI is much greater than the danger of AI is much greater than the the<00:00:03.120><c> danger</c><00:00:03.600><c> of</c><00:00:03.780><c> nuclear</c><00:00:04.140><c> warheads</c><00:00:04.560><c> by</c><00:00:04.799><c> a</c><00:00:04.980><c> lot</c> okay okay okay so so so if<00:00:13.200><c> we</c><00:00:13.380><c> start</c><00:00:13.500><c> with</c><00:00:13.679><c> that</c><00:00:13.799><c> first</c><00:00:13.920><c> statement</c> if we start with that first statement if we start with that first statement the<00:00:15.299><c> danger</c><00:00:15.599><c> of</c><00:00:15.780><c> AI</c> the danger of AI the danger of AI is<00:00:17.640><c> much</c><00:00:18.000><c> greater</c><00:00:18.240><c> than</c><00:00:18.300><c> that</c><00:00:18.420><c> of</c><00:00:18.600><c> nuclear</c> is much greater than that of nuclear is much greater than that of nuclear warheads I<00:00:22.140><c> don't</c><00:00:22.199><c> think</c><00:00:22.380><c> that's</c><00:00:22.939><c> exactly</c><00:00:23.939><c> accurate</c> I don't think that's exactly accurate I don't think that's exactly accurate right<00:00:25.019><c> now</c> right now right now I<00:00:27.180><c> think</c><00:00:27.420><c> it</c><00:00:28.140><c> could</c><00:00:28.320><c> be</c><00:00:28.439><c> true</c><00:00:28.820><c> in</c><00:00:29.820><c> the</c><00:00:29.880><c> future</c> I think it could be true in the future I think it could be true in the future but<00:00:31.740><c> at</c><00:00:32.099><c> the</c><00:00:32.220><c> current</c><00:00:32.460><c> state</c><00:00:32.700><c> of</c><00:00:32.880><c> Technology</c> but at the current state of Technology but at the current state of Technology I<00:00:34.800><c> will</c><00:00:35.040><c> take</c><00:00:35.219><c> AI</c><00:00:35.700><c> over</c><00:00:36.059><c> Warheads</c>",
  "transcript_source": "youtube-subs"
}