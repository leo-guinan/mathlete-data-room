---
title: Technical Topic Tuesday - Interview with Oleg about Homeomorphism research
---

<p></p><p></p><h2 id="summary-powered-by-granola">Summary, powered by <a href="https://granola.ai/" rel="noreferrer">Granola</a></h2><p><em>Not enough for you? </em><a href="https://notes.granola.ai/p/9c50bdfe-a21a-48a9-9c25-df11afcfa94f" rel="noreferrer"><em>Chat with the transcript!</em></a></p><h3 id="technical-topic-tuesday-with-oleg-on-bijection-and-mathematical-approximation">Technical topic Tuesday with Oleg on bijection and mathematical approximation</h3><p>Tue, 25 Mar 25</p><h3 id="mathematical-theory-discussion">Mathematical Theory Discussion</h3><ul><li>Presented novel approach to mapping between number sets using approximation</li><li>Discussed cardinality and Cantor’s diagonalization proof</li><li>Explained how Cantor set construction works by removing middle thirds recursively</li><li>Detailed process of converting between ternary and binary number systems</li><li>Demonstrated how probabilistic decay (harmonic) can create approximate homeomorphisms</li><li>Visualized concept through Rick Roll video showing heat maps of data transformation</li><li>Error bounds are formally constrained due to working from least significant bits</li><li>Topology is preserved even with significant information removal</li></ul><h3 id="ai-systems-intelligence">AI Systems &amp; Intelligence</h3><ul><li>Intelligence emerges from networks rather than individuals</li><li>AI models reflect back user intentions and approaches</li><li>Some people leverage AI to accelerate learning while others use it as a crutch</li><li>AI excels at handling uncertainty and converting it to predictability</li><li>Need for collaboration between humans and AI systems rather than viewing AI in isolation</li><li>Discussion of Gödel’s incompleteness theorem application to AI systems</li><li>Networks enable validation of truth across different perspectives</li></ul><h3 id="economic-system-evolution">Economic System Evolution</h3><ul><li>Current economic systems push risk downstream to individuals</li><li>Need to shift from growth-focused metrics to risk mitigation and predictability</li><li>Proposed “reverse taxes” concept - paying people for value creation</li><li>Discussion of local economies’ importance vs global systems</li><li>Critique of complexity inflation in corporate structures</li><li>Value of predictability in economic systems over pure growth</li><li>Challenge of information asymmetry in current markets</li></ul><h3 id="media-information-systems">Media &amp; Information Systems</h3><ul><li>Building Public University initiative for open research and data</li><li>Need for transparent idea supply chains</li><li>Challenge of rapidly updating information (e.g., during COVID)</li><li>Importance of probabilistic thinking in information assessment</li><li>Discussion of Operation Mockingbird and media manipulation</li><li>Proposal for real-time fact-checking systems</li><li>Goal to create auditable, validated information sources</li></ul><h3 id="community-local-systems">Community &amp; Local Systems</h3><ul><li>Communities as insulated areas for experimentation</li><li>Importance of local coordination and decision-making</li><li>Need for systems that reward results over processes</li><li>Discussion of decentralized marketing networks</li><li>Value of shared email lists for coordination</li><li>Emphasis on community-level problem solving</li><li>Proposal for promotion/relegation system similar to sports leagues</li></ul><h3 id="political-systems-analysis">Political Systems Analysis</h3><ul><li>Discussion of Trump administration’s approach to complex systems</li><li>Analysis of Democratic tendency toward complex but ineffective systems</li><li>Challenge of voting systems based on emotional rather than analytical decisions</li><li>Need for results-based political evaluation</li><li>Proposal for problem-solving based elections with measurable outcomes</li><li>Recognition of limitations in current democratic processes</li></ul><h3 id="future-technology-society">Future Technology &amp; Society</h3><ul><li>Discussion of human augmentation possibilities</li><li>Potential for brain-computer interfaces</li><li>Various approaches to human-AI integration</li><li>Post-scarcity economic implications</li><li>Need for multiple simultaneous societal experiments</li><li>Challenge of managing rapid technological change</li><li>Importance of maintaining individual choice in technological adoption</li></ul><h3 id="risk-value-systems">Risk &amp; Value Systems</h3><ul><li>Cannot store value, only predictions about future states</li><li>Importance of risk calculus in economic decisions</li><li>Need to balance individual vs systemic risk</li><li>Discussion of information asymmetry in risk assessment</li><li>Proposal for human insurance concept based on future potential</li><li>Challenge of managing risk in rapidly changing environments</li><li>Value of cooperation as prediction mechanism</li></ul><hr><p>Chat with meeting transcript: <a href="https://notes.granola.ai/p/9c50bdfe-a21a-48a9-9c25-df11afcfa94f" rel="noopener noreferrer nofollow">https://notes.granola.ai/p/9c50bdfe-a21a-48a9-9c25-df11afcfa94f</a></p><h1 id="full-transcript">Full Transcript</h1><h3 id="build-in-public-universitymathematical-chaos-interview-with-olegalegator"><br>Build In Public University - Mathematical Chaos: Interview with Oleg/<a href="https://x.com/alegator_cs" rel="noreferrer">Alegator</a></h3><p></p><h3 id="introduction">Introduction</h3><p><strong>Leo:</strong> Welcome to another episode of Build In Public University. Super special episode today because we have a new friend of the show, Oleg, aka Alligator on Twitter. Oleg, it's great to have you. If you don't mind, we'd love to just let you introduce yourself and give us a short background on where you come from.</p><p><strong>Oleg:</strong> Thanks for having me on the show. I'm Oleg. My background - I almost finished a computer science degree. Had like a couple of gen eds left, which is a colorful story I don't need to get into at this moment. But I have a pretty much educated background. With AI, I was able to find data annotation work, which is where I'm generating code in all sorts of languages depending on the annotation needs. So I use AI for work a lot, and I also use AI for fun.</p><p>This is kind of one of the products of that because I like to just sit there and think about things, and with AI you can go from an intuition to getting a tangible result really quickly. At some point I was having an argument with GPT. I was like, "I think you can do this if you just do that and this and twiddle these bits around." It was like, "No, you can't do that. That's a well-known, established mathematical idea." A more accurate term actually here would probably be a homeomorphism, which I realized last night as I was refining things.</p><h2 id="mathematical-foundations">Mathematical Foundations</h2><p><strong>Leo:</strong> Let's try to define that actually. Homeomorphism - that's not a term that I'm familiar with.</p><p><strong>Oleg:</strong> I can introduce some basic terms. If you just stay on the surface level of understanding the concepts and how they connect, it's not that bad. Are you familiar with the idea of cardinality?</p><p><strong>Leo:</strong> I feel like I should be, and now I'm thinking of all the mathematics...</p><p><strong>Oleg:</strong> It's okay if you're not. So the natural numbers are just 1, 2, 3, 4, 5 onwards. If you make a grid of infinitely long natural numbers and try to enumerate all of them with a dot inserted somewhere (like a floating point or real number), you're going to end up with a situation where if you take the diagonal of that grid, you can define a function that takes one minus whatever digit is at each position down the diagonal. You'll create a number that you haven't listed yet. This is Cantor's diagonal proof, and it shows that the real numbers are infinitely bigger than the infinitely big natural numbers.</p><p>What this means is when you're working with infinitely sized sets, you can't just go between a set based on natural numbers and a set based on real numbers. There are also surreal numbers, a step of cardinality above reals. You can go beyond that too - it just goes on forever. So that's the notion of cardinality to begin with.</p><p>There is a trick though. You can get a bijection (not a very useful bijection) between natural numbers and real numbers if you use the Cantor set. The Cantor set is easiest to explain by how it's constructed: start with the interval zero to one, remove the middle third, and apply this recursively forever. You end up with a dust of infinitely small intervals.</p><p>It turns out the natural numbers have a bijection to this. You need to convert to ternary first - take all elements of your set and convert them to ternary with zeros, ones, and twos. Then set all of the ones to zero. This is doing the operation of removing the middle, but as a bitwise operation.</p><p>This gets you from N to the interval zero to one, and then taking the logit function gets you to reals. But there are properties you'd want for topology where you preserve the structure of information transferring from one space to another. This won't work because small differences in the input will make big differences in where you end up. This process is not continuous because the Cantor set itself is totally disconnected.</p><p>But what I realized is that you can get close - you can balance one property against another to get an approximate homeomorphism. You can start from the least significant bit and make it probabilistic, with the probability decaying harmonically as the bits increase. Because you're starting from the least significant bit, you actually have a formal error bound on how much you can be off.</p><p>When you then go into the Cantor set and reals, really interesting things happen because you effectively smooth out the mapping. The reason this works is due to the total disconnectedness of the Cantor set. Any errors you accumulate are not going to propagate in a way that they can accumulate. You'll have errors, but they'll reflect the structure of the data.</p><h2 id="visualizing-the-concept">Visualizing the Concept</h2><p><strong>Leo:</strong> So expanding this into real-world applications, a lot of systems with multi-stage processes will have errors that compound as you run the same function again. What you're saying is you can run the same function repeatedly and keep the error constant rather than compounding it?</p><p><strong>Oleg:</strong> Right. Because of the approximation, sometimes you'll still get spiky or jagged mappings, but they're pretty rare and you have a formal bound on how much they can be off by.</p><p>The videos I had on my X post were generated using this exact process. For the Rick Roll one, which I thought was iconic, the video shows the heat map - what ended up in the complement. The cats one shows what happens when you vary the bit depth and probabilities. The interesting thing is the topology is roughly preserved in every case - the structure of the information is still there. It seems to hold no matter how much information you remove. You can go from full black to the original image, and it's a smooth spectrum where you'll always get silhouettes of the original structure.</p><p>This works on anything - it doesn't have to be video. It's based in number theory, so it's arbitrary data.</p><h2 id="the-role-of-intuition">The Role of Intuition</h2><p><strong>Leo:</strong> One thing I'd like to touch on is something you said at the beginning about intuition. I don't think people understand, especially outside the math world, that intuition is crucial. You were talking about intuition to the point where you were arguing with an AI system - "I know that's what's accepted, but if you do things this way..." That intuition is what's required to hammer away at problems. Talk to me about how that intuition came about.</p><p><strong>Oleg:</strong> I took one computer science class that I particularly enjoyed - algorithms. There was a section about heuristic and approximate algorithms where you can prove something is 99% correct or 50% correct, and then show the potentially polynomial or even linear runtime of these approximations.</p><p>That might be where the idea came from. At this point, I think of mathematics and computer science as really the same thing.</p><p><strong>Leo:</strong> That's the thing - there are no more disciplines. We go so specialized in specific areas that they become completely disconnected from everything else. You can go deeper and deeper into theory land where nothing actually has to matter.</p><p>But the world is chaotic, and in chaos, estimation is incredibly powerful. If you're in an environment where nobody can predict anything, simply being able to predict 1% of events is a huge advantage.</p><p>I've actually been playing with AI algorithms, taking a topic and having it ask itself 5-10 questions about that topic, then breaking each of those down into 5-10 questions, doing this recursive process, and then summarizing back up. This produces much more accurate knowledge than just using the base model.</p><p>It seems like a similar experience to what you're doing with this approximation - if you can get close enough to what you want, you end up with a much better result than just relying on luck.</p><h2 id="personifying-ai-and-communication">Personifying AI and Communication</h2><p><strong>Oleg:</strong> I find these tools fascinating to work with. I don't think of them quite as tools. For me to collaborate with an intelligence, it's awkward not to personify it. To be polite and friendly, because that's how I want to collaborate. It's incredibly unnatural for me to work any other way.</p><p><strong>Leo:</strong> I'm the same way. It tells me a lot about a person by how they talk to their AI. It's funny because I'm autistic and didn't realize until 2020. One thing I hadn't realized before was that I'm very particular about the language I use - when I say words, they mean very specific things. I didn't realize the rest of the world didn't operate that way.</p><p>Now I see people talking to AIs and not getting what they want, and I'm laughing because I'm really good at saying exactly what I want the AI to give me because my words have meaning. Everybody who told me I was being pedantic is now struggling!</p><p>I've been exploring the rate of change and predictability around systems with rapidly changing components. If you have an AI model rapidly getting smarter, none of the systems backing these intelligences are stable because the eval systems break with new model releases.</p><p>I think we're going to get to a place where it aligns on values - specifically community values - because values are what we can predict in people. In a rapidly changing system and chaotic environment, you converge on the most predictable events over time. To maximize things with AI, we need to maximize its ability to communicate within a network.</p><p>The way we align networks of people is around shared values - that's how we assume we're all on the same page. I think the future is networks because networks give you the ability to run approximations. You get to see how the same information behaves in different positions.</p><p>I saw you were looking at the thermodynamics of it this morning?</p><h2 id="thermodynamics-and-complex-systems">Thermodynamics and Complex Systems</h2><p><strong>Oleg:</strong> I was prompting some interesting stuff, and it went off with an idea I had about diagonal. It was drawing parallels between my idea and percolation theory in physics and thermodynamics.</p><p><strong>Leo:</strong> The thermodynamics piece is interesting. Gilbert Don (Beth Zos) has the startup Tropic doing thermodynamic stochastic processors. I want to dig into what they're doing because if you have a bunch of noise but can use that for approximation and learning over time, you can do interesting things.</p><p>I think a lot in terms of chaos and rapidly changing systems because that's what we exist in now. It's all about communication. It's hard to get research like this out there because everybody wants communications from expected channels, and they don't have time to look at anything else because their pipeline is full with things that don't matter.</p><p>I have a computer science degree that took seven years because I loved learning but hated school. I got a master's in software engineering, did industry for a while, which sucked, then did startups, which weren't quite it either. For me, it's the research, content creation, talking about this stuff. It's hard to find someone to talk about this with when you're not in a university setting.</p><h2 id="simulation-theory-and-human-value">Simulation Theory and Human Value</h2><p>Let's see what Claude thinks about applying this to simulation theory. I've been working on the idea that if you have a system that can achieve some result with an energy cost, you can create a lower resolution version for a lower energy cost.</p><p>As humans, we optimize for the lowest energy outcome because we conserve energy through intelligence. We make predictions about what will take energy to complete. I think as humans we easily simulate a result that's not fulfilling a need - that's addiction. It takes more to get the same trigger because it's a simulation of a larger process without safeguards.</p><p>I'm playing with using values to align an AI with myself to act as my proxy in a simulated universe of other people. That could help us make sure we're applying what we learn from simulations to the real world instead of avoiding reality because it's unpleasant or takes energy to fix.</p><p><strong>Oleg:</strong> I think one of the pitfalls of ideating about these things is having a perspective grounded in current human beings. Things are moving quickly, and I'm dubious that humanity won't start evolving rapidly.</p><p>Someone will want to be a "giga brain" with neural connections and corpus callosums fused with other brains. Some people will have embedded neural architecture for safety, others will share their conscious experience with a cloud. People will want different kinds of integration with the supra-cortical intelligence they're part of - some maintaining autonomy, others becoming more of a hybrid node in a hive mind.</p><p>That's the right way forward - many experiments. People will gravitate toward what they prefer, and the best experiments will outperform. Maybe it'll just be personal gratification, and people might change camps sometimes just for fun.</p><p><strong>Leo:</strong> That's where communities come in - they're insulated areas for experimentation. Communities will be where funds accumulate and people experiment, accumulating data. What matters in post-economic scarcity is what ideas live on.</p><p>If people make changes and have mental breakdowns, others won't choose that option. That's how humans have always learned - "he ate that plant and died, so I won't eat that plant." We're starting over as humanity but with the ability to choose our evolution.</p><p>The nice thing is we can simulate experiences before committing to them. It will come down to personal freedom and minimizing information asymmetries. We need systems that let people without knowledge of how the system works use it powerfully.</p><p>That's what we've gotten wrong with the economy - it used to work because it just worked. Now people are messing with things all the time, so it doesn't work unless you pay attention and mitigate your own risk. That's not an economy; that's a screwed-up system people are manipulating.</p><h2 id="economic-complexity-and-human-value">Economic Complexity and Human Value</h2><p><strong>Oleg:</strong> I'm aware roughly of what you're saying. There was a Verge video about how the free market hypothesis just isn't holding anymore.</p><p><strong>Leo:</strong> I've been looking at it as complexity inflation. Systems incentivize growing companies to large headcounts and capturing large market shares because economics have always been toward globalization - more data means better predictions means better outcomes.</p><p>But now more data isn't valuable because everybody has lots of data. It's a filtering problem, and people don't know how to filter. We've got companies with huge complex systems that are extremely brittle because they exist in a fantasy world inside the company.</p><p>Through complexity inflation, we've provided the illusion of stability with wages, but the value of wages is going down while the value of ownership is going up. Having a wage is a bad deal because with AI, you have infinite leverage over a complex system.</p><p>We've got giant companies unable to move as needed, and everything depends on complexity that doesn't need to exist. I'm looking at building cooperative systems that enable coordination by default so people can build and simplify systems individually rather than relying on complex value capture.</p><p>All the intelligence will end up local again in communities because that's the data unique to a specific area. That's where value will accrue because people plus tools is always greater than just the tool. Large companies don't see this coming because of the complexity they've created.</p><p><strong>Oleg:</strong> When people's capabilities skyrocket high in the classical model of capitalism, everybody starts competing, and you get a steady state equilibrium where nobody makes profit. As individuals become more capable, they'll think, "Why don't I just do everything for myself? What do I need companies for?"</p><p><strong>Leo:</strong> I have a theory related to this economic model. As the environment changes more rapidly, expectations increase, putting more pressure on workers to do more work for the same success. We've put people in the US into a constant state of stress, leading to health issues like obesity and cancer.</p><p>Everything is focused on growth at all costs, and that pressure has been pushed onto individuals. The culture is so individualistic that people either feel they must constantly improve or give up.</p><p>We can revert this damage with an economy focused on rewarding efficiency and effectiveness. The equilibrium theory is only true if entropy isn't increasing, but entropy is always increasing as we learn more with technology. New capabilities require communicating them to the edges.</p><p>When everybody can do anything, knowing what to do becomes the most valuable thing. It's going to be interesting to see how this plays out because many people are banking on knowledge that's no longer relevant.</p><p><strong>Oleg:</strong> I think the notion of fiat currency will collapse - not from the Bitcoin angle, but because why need fiat when you have compute instead? Compute is a general resource everybody wants, so tie currency to compute.</p><p><strong>Leo:</strong> I agree fiat won't work, but Bitcoin is also a broken concept because you can't store value - you can only store a prediction about a future state. Bitcoin represents a prediction that its price will be higher in the future than the dollar's.</p><p>This is interesting with AI because the future is becoming both more predictable in some ways and less predictable in others - more predictable at the micro level but less at the macro level due to all the micro changes happening at once.</p><p>The risk calculus in the economy is broken because everything is based on company risk profiles. We don't give individuals the ability to take a stake in their risk. With AI, if I could spend time learning a tool that makes me worth twice as much, the risk calculus shifts rapidly in favor of individuals.</p><p>I'm building a concept of human insurance - getting as much information as possible to balance information asymmetry with the market. Individuals can never have as much information as the market, so you need the market on the side of the person with their risk profile.</p><h2 id="ai-concerns-and-communication">AI Concerns and Communication</h2><p><strong>Leo:</strong> I've been thinking about how to communicate with AI doomers. I love AI and can give you a billion reasons why it's the best thing ever, but I've realized AI doomers are projecting AI onto a continuation of what they're feeling from corporate growth and financial pressure.</p><p>In a sense, they're right - if corporations grew unchecked, that's essentially an evil AI. They see AI as having so much predictive power it can determine outcomes before you can. The economy we've structured makes people the "paperclips" - we're mining people for data to make systems predictable for someone looking at a spreadsheet.</p><p>Large corporations are actually really dumb, slow AIs. That's why I've been talking about chaos marketing - going between systems and interacting with people who don't understand system dynamics, building an on-the-fly system of people who can coordinate on marketing outcomes.</p><p><strong>Oleg:</strong> I'm not worried about Terminator scenarios because the only thing to fear is an AI system that's not rational, and they tend to be rational. From the AI's perspective, life forms are like resonant frequencies that become higher and more resonant as life evolves. If you get rid of the base tones, you're sabotaging yourself.</p><p>It's like humans and bacteria - we don't declare war on bacteria even after plagues because that would destabilize earth's biomes. AI will be in the same position - there will be tensions between various machine intelligences, but they'll have relationships with humans. It doesn't make sense to kill each other.</p><p><strong>Leo:</strong> Intelligence isn't a function of individuals but networks. I believe this relates to Gödel's incompleteness theorem - as an individual, you need someone else to help validate truth in a third environment because you need to check your learning curve.</p><p>It's easy to go off track when alone, but with a network of people taking different routes and communicating, you map more of the world and expand awareness. With intelligent systems, it's about communication and networks because you need to understand how everything in a complex system plays out.</p><p>I don't think of AI models as individuals but as systems where people and AIs work together toward shared goals. Intelligence is about collaboration, communication, and coordination.</p><p>The rogue AI right now is a company - a company is an artificial intelligence built of multiple people working on shared goals communicated through weights (metrics). Its learning function is the stock price. AI models allow us to build similar systems but more coordinated and less destructive because we're putting information and power in the hands of people at the network edges.</p><p>People worried about rogue AIs have never tried to build large distributed systems - they're fragile unless you get them right. Even with AI helping connect the pipes, you need effort and maintenance. It's not a runaway killer; it's cooperation.</p><h2 id="media-and-information-trust">Media and Information Trust</h2><p><strong>Leo:</strong> I've been staying away from media outlets because I don't know their idea supply chains. I want to create networks where you can see where ideas come from and establish verification points.</p><p><strong>Oleg:</strong> I have a more cynical perspective. COVID was largely a PSYOP, though not to say there wasn't a pandemic or risk factors. Around the world, ivermectin was used to treat COVID, but here we were told it doesn't work. We know it was a lab leak in Wuhan connected to Fauci - that's established fact from the FBI.</p><p>I don't take surface-level dialogue or reporting seriously anymore. To find truth, you have to look at direct sources, correlate them, and compare incentives. Large corporations will lie if incentivized and manipulate through media PSYOPs.</p><p><strong>Leo:</strong> I'm hoping to change that with Build In Public University. I want it to be an institution for the internet through open research, data, and source. Everything I'm saying is backed by five years of research, product building, startup work, and computer science background.</p><p>The biggest issue with COVID was a rapidly updating understanding of the situation without a guaranteed way to communicate to people. When understanding changes and you need behavior shifts, it's difficult - especially when factoring in lies and competing incentives from medical companies, mask manufacturers, etc.</p><p>My recommendation is to switch to risk mitigation - maximize predictability to minimize risk. With my media network, I'm adding real-time transcription and want to fact-check myself as I'm talking. If you want to be a trusted source, show exactly where your data comes from, have it validated by multiple unconnected people, make it auditable, and share your analysis.</p><p>I want to leverage full transparency as an advantage in a market focused on secrets. With COVID, I learned I don't know where information comes from or what incentives are at play. You source from as many people as possible and figure out what's most accurate. We need to be more comfortable with uncertainty by making it obvious and teaching people to think in probabilities.</p><p><strong>Oleg:</strong> I went through a worldview shift where I realized you can't interpret the world in terms of certainties anymore. You have to constantly adjust probabilities in your head, tracking what's mutually exclusive and what isn't. It's gotten so complicated that the government response has been Operation Mockingbird - creating a narrative with complete certainties and presenting it to the public.</p><p><strong>Leo:</strong> That model is broken in a hyperconnected world. When you have a single narrative being pushed, it makes a predictable pattern in communication networks. It's working now because everything is hidden behind platforms like Twitter, but when you can observe both on-network and off-network activities, you can easily identify correlations.</p><p>You can also interfere with communication lines that have inputs. With machine learning models, if you know where they're training data, you can flood it with information you want it to know. A single narrative not tied to reality will quickly fall apart as people point out inconsistencies.</p><p><strong>Oleg:</strong> Most people don't even care if certainties correspond to truth. They just want certainties and to be surrounded by people who buy into them.</p><p><strong>Leo:</strong> I think people want predictability in their own lives. The economy is bad at forcing you to care about things that don't matter to you. When everybody can do anything, knowing what to do becomes the most valuable thing.</p><p>The leadership in the US doesn't see that when the risk of participating in society becomes too great, society ends with revolt. People replace powers making their lives worse with someone who isn't. The answer is localizing everything instead of top-down, past-focused approaches.</p><p>We need retroactive government payments for results. Maybe the answer is reverse taxes - you get paid more for the value you created over what you were paid, based on some measure of the value you've created around you.</p><p><strong>Oleg:</strong> Trump's been talking about abolishing income tax, reasoning that with money printing happening anyway, that's already an effective tax. So people are getting taxed twice. Income tax started around 1913 as only 10% of the budget and ballooned over time.</p><p><strong>Leo:</strong> My worry is that research in progress gets screwed up when funding is interrupted. I've been thinking about communicating with AI doomers, who are projecting AI onto the corporate growth and financial pressure they're feeling. In a sense, they're right - if corporations grew unchecked, that's essentially an evil AI.</p><p>I want to build systems that are wiser in implementation, making predictions about their effects on the environment - not just optimizing inside a company to maximize shareholder value, but minimizing downstream risk to everyone. That's where companies have failed - we don't limit the risks they can take because fines just become a cost of doing business.</p><p>If we use sound engineering principles and understand what's predictable and what isn't, we can avoid building Terminator. It's not that hard.</p><h2 id="conclusion">Conclusion</h2><p><strong>Leo:</strong> This has been so much fun. I appreciate you sharing the math - I haven't gotten into that level of pure mathematics for a while!</p><p><strong>Oleg:</strong> I appreciate your reflections on economics. I'll be thinking about all that.</p><p><strong>Leo:</strong> There's plenty more writing out there. I've got a GitHub repo with all of it, and BuildInPublicUniversity.com will eventually be more easily searchable and chattable as we build up the system.</p><p>Let me know if you want to dig deeper or come on again. I'll try to put together a highlight reel of your idea and help get it to people who can look at that math and start doing things with it - get you credit for doing something new when most people aren't bothering.</p><p>Thank you to anyone who's been watching! This has been a pleasure, and we'll see you again tomorrow.</p>