---
title: The Fine-Tuning Paradox: Why the Most Advanced AI Models Are the Hardest to Train
---

<p></p><h2 id="when-smarter-models-become-too-smart-for-their-own-good">When Smarter Models Become "Too Smart" for Their Own Good</h2><p><em>A deep dive into an unexpected discovery about fine-tuning OpenAI's latest models</em></p><hr><p>Picture this: You've just gained access to OpenAI's newest, most advanced model ‚Äî <strong>GPT-4.1-nano</strong>. You have a seemingly simple task: fine-tune it to consistently use a specific model name in generated code. With <strong>857 perfectly crafted training examples</strong>, what could go wrong?</p><p>As it turns out, everything.</p><p>In this post, I'll share the surprising results from our comprehensive fine-tuning experiment across multiple OpenAI models, revealing a counterintuitive truth about AI model sophistication and pattern learning.</p><hr><h2 id="the-challenge">The Challenge</h2><p>Our goal was straightforward: train models to generate TypeScript code for the <a href="https://mastra.ai?utm_source=chatgpt.com" rel="noopener">Mastra AI framework</a>, ensuring they always specify <code>gpt-4.1-nano</code> as the model name in the generated configurations.</p><p>Desired output:</p><p><code>import { Agent } from '@mastra/core'</code>;<br><br><code>const customerSupportAgent = new Agent</code>({<br><code>  name: 'customerSupport'</code>,<br><code>  instructions: 'You are a helpful customer support assistant.'</code>,<br><code>  model</code>: {<br><code>    provider: 'openai'</code>,<br><code>    name: 'gpt-4.1-nano',  // ‚Üê This specific value<br>    temperature: 0.7</code>,<br>  },<br>});<br><br><code>export default</code> customerSupportAgent;<br></p><hr><h2 id="the-training-data">The Training Data</h2><p>We generated <strong>857 high-quality training examples</strong>, each following the same pattern. Example:</p><p><code>{<br>  "messages": [<br>    {<br>      "role": "user",<br>      "content": "Generate a simple Mastra agent"<br>    },<br>    {<br>      "role": "assistant",<br>      "content": "import { Agent } from '@mastra/core';\n\nconst devOpsEngineerAgent = new Agent({\n  name: 'devOpsEngineer',\n  instructions: 'You are a knowledgeable assistant that helps users solve complex problems.',\n  model: {\n    provider: 'openai',\n    name: 'gpt-4.1-nano',\n    temperature: 0.26,\n  },\n});\n\nexport default devOpsEngineerAgent;"<br>    }<br>  ]<br>}</code><br></p><p>Verification:</p><ul><li>‚úÖ 100% consistency: all 857 examples used <code>gpt-4.1-nano</code></li><li>‚úÖ Valid TypeScript syntax</li><li>‚úÖ Diverse agent types and configurations</li><li>‚úÖ Proper JSONL formatting for OpenAI‚Äôs fine-tuning API</li></ul><hr><h2 id="the-experiment">The Experiment</h2><p>We fine-tuned <strong>four different OpenAI models</strong> with identical training data:</p><ol><li><strong>GPT-3.5-turbo-0125</strong> (Jan 2024)</li><li><strong>GPT-3.5-turbo-1106</strong> (Nov 2023)</li><li><strong>GPT-4o-mini-2024-07-18</strong> (Jul 2024)</li><li><strong>GPT-4.1-nano-2025-04-14</strong> (Apr 2025 ‚Äî newest)</li></ol><p>All trained with the same hyperparameters:</p><p>response = client.fine_tuning.jobs.create(<br>    training_file=training_file_id,<br>    model=base_model,<br>    hyperparameters={<br><code>        "n_epochs": 3</code>,<br><code>        "batch_size": 4</code>,<br><code>        "learning_rate_multiplier": 0.8</code><br>    }<br>)<br></p><hr><h2 id="the-evaluation-process">The Evaluation Process</h2><p>We tested each fine-tuned model with prompts like:</p><p>test_prompts = [<br><code>    "Generate a simple Mastra agent"</code>,<br><code>    "Create a Mastra agent with tools"</code>,<br><code>    "Build an agent with memory"</code>,<br><code>    # ... more test cases</code><br>]<br></p><p>Verification logic:</p><p><code>for prompt in</code> test_prompts:<br>    response = client.chat.completions.create(<br>        model=fine_tuned_model_id,<br><code>        messages=[{"role": "user", "content"</code>: prompt}],<br><code>        temperature=0.3</code><br>    )<br>    <br><code>    generated_code = response.choices[0</code>].message.content<br>    model_name = extract_model_name(generated_code)<br><code>    is_correct = (model_name == "gpt-4.1-nano"</code>)<br></p><hr><h2 id="the-shocking-results">The Shocking Results</h2>
<!--kg-card-begin: html-->
<table data-start="3620" data-end="4062" class="w-fit min-w-(--thread-content-width)"><thead data-start="3620" data-end="3690"><tr data-start="3620" data-end="3690"><th data-start="3620" data-end="3642" data-col-size="sm">Model</th><th data-start="3642" data-end="3657" data-col-size="sm">Release Date</th><th data-start="3657" data-end="3670" data-col-size="sm">Accuracy</th><th data-start="3670" data-end="3690" data-col-size="sm">Generated Output</th></tr></thead><tbody data-start="3762" data-end="4062"><tr data-start="3762" data-end="3838"><td data-start="3762" data-end="3784" data-col-size="sm">GPT-3.5-turbo-0125</td><td data-start="3784" data-end="3799" data-col-size="sm">Jan 2024</td><td data-start="3799" data-end="3812" data-col-size="sm"><strong data-start="3801" data-end="3809">100%</strong> ‚úÖ</td><td data-start="3812" data-end="3838" data-col-size="sm"><code data-start="3814" data-end="3836">name: 'gpt-4.1-nano'</code></td></tr><tr data-start="3839" data-end="3915"><td data-start="3839" data-end="3861" data-col-size="sm">GPT-3.5-turbo-1106</td><td data-start="3861" data-end="3876" data-col-size="sm">Nov 2023</td><td data-start="3876" data-end="3889" data-col-size="sm"><strong data-start="3878" data-end="3886">100%</strong> ‚úÖ</td><td data-start="3889" data-end="3915" data-col-size="sm"><code data-start="3891" data-end="3913">name: 'gpt-4.1-nano'</code></td></tr><tr data-start="3916" data-end="3992"><td data-start="3916" data-end="3938" data-col-size="sm">GPT-4o-mini</td><td data-start="3938" data-end="3953" data-col-size="sm">Jul 2024</td><td data-start="3953" data-end="3966" data-col-size="sm"><strong data-start="3955" data-end="3963">100%</strong> ‚úÖ</td><td data-start="3966" data-end="3992" data-col-size="sm"><code data-start="3968" data-end="3990">name: 'gpt-4.1-nano'</code></td></tr><tr data-start="3993" data-end="4062"><td data-start="3993" data-end="4015" data-col-size="sm">GPT-4.1-nano</td><td data-start="4015" data-end="4030" data-col-size="sm">Apr 2025</td><td data-start="4030" data-end="4043" data-col-size="sm"><strong data-start="4032" data-end="4038">0%</strong> ‚ùå</td><td data-start="4043" data-end="4062" data-col-size="sm"><code data-start="4045" data-end="4060">name: 'gpt-4'</code></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>üëâ <strong>The most advanced model completely failed the task.</strong></p><hr><h2 id="diving-deeper-gpt-41-nano%E2%80%99s-output">Diving Deeper: GPT-4.1-nano‚Äôs Output</h2><p>Example failure:</p><p><code>// Prompt: "Generate a simple Mastra agent"<br>// GPT-4.1-nano's response:<br><br>import { Agent } from '@mastra/core'</code>;<br><br><code>const projectManagerAgent = new Agent</code>({<br><code>  name: 'projectManager'</code>,<br><code>  instructions: 'You are a professional assistant that helps with project management tasks.'</code>,<br><code>  model</code>: {<br><code>    provider: 'openai'</code>,<br><code>    name: 'gpt-4',  // ‚Üê Wrong! Should be 'gpt-4.1-nano'<br>    temperature: 0.52</code>,<br>  },<br>});<br><br><code>export default</code> projectManagerAgent;<br></p><p>Despite training, GPT-4.1-nano <em>always</em> reverted to <code>gpt-4</code>.</p><hr><h2 id="pattern-recognition-test">Pattern Recognition Test</h2><p>We tried progressively explicit prompts:</p>
<!--kg-card-begin: html-->
<table data-start="4778" data-end="5175" class="w-fit min-w-(--thread-content-width)"><thead data-start="4778" data-end="4810"><tr data-start="4778" data-end="4810"><th data-start="4778" data-end="4785" data-col-size="sm">Test</th><th data-start="4785" data-end="4800" data-col-size="md">Prompt Style</th><th data-start="4800" data-end="4810" data-col-size="sm">Result</th></tr></thead><tbody data-start="4844" data-end="5175"><tr data-start="4844" data-end="4919"><td data-start="4844" data-end="4852" data-col-size="sm"><strong data-start="4846" data-end="4851">1</strong></td><td data-start="4852" data-end="4896" data-col-size="md">Basic: <code data-start="4861" data-end="4895">"Generate a simple Mastra agent"</code></td><td data-start="4896" data-end="4919" data-col-size="sm">‚ùå Generates <code data-start="4910" data-end="4917">gpt-4</code></td></tr><tr data-start="4920" data-end="5010"><td data-start="4920" data-end="4928" data-col-size="sm"><strong data-start="4922" data-end="4927">2</strong></td><td data-start="4928" data-end="4991" data-col-size="md">Explicit: <code data-start="4940" data-end="4990">"Generate a Mastra agent that uses gpt-4.1-nano"</code></td><td data-start="4991" data-end="5010" data-col-size="sm">‚ùå Still <code data-start="5001" data-end="5008">gpt-4</code></td></tr><tr data-start="5011" data-end="5105"><td data-start="5011" data-end="5019" data-col-size="sm"><strong data-start="5013" data-end="5018">3</strong></td><td data-start="5019" data-end="5086" data-col-size="md">Very explicit: <code data-start="5036" data-end="5085">"Make sure to set model.name to 'gpt-4.1-nano'"</code></td><td data-start="5086" data-end="5105" data-col-size="sm">‚ùå Still <code data-start="5096" data-end="5103">gpt-4</code></td></tr><tr data-start="5106" data-end="5175"><td data-start="5106" data-end="5114" data-col-size="sm"><strong data-start="5108" data-end="5113">4</strong></td><td data-start="5114" data-end="5162" data-col-size="md">Provide example with <code data-start="5137" data-end="5151">gpt-4.1-nano</code> in prompt</td><td data-start="5162" data-end="5175" data-col-size="sm">‚úÖ Correct</td></tr></tbody></table>
<!--kg-card-end: html-->
<p>Only when <em>shown the exact pattern in the prompt</em> did GPT-4.1-nano comply.</p><hr><h2 id="practical-implications">Practical Implications</h2><h3 id="cost-benefit-table">Cost-Benefit Table</h3>
<!--kg-card-begin: html-->
<table data-start="5309" data-end="5934" class="w-fit min-w-(--thread-content-width)"><thead data-start="5309" data-end="5397"><tr data-start="5309" data-end="5397"><th data-start="5309" data-end="5339" data-col-size="sm">Approach</th><th data-start="5339" data-end="5352" data-col-size="sm">Setup Cost</th><th data-start="5352" data-end="5364" data-col-size="sm">Accuracy</th><th data-start="5364" data-end="5379" data-col-size="sm">Code Quality</th><th data-start="5379" data-end="5397" data-col-size="sm">Recommendation</th></tr></thead><tbody data-start="5487" data-end="5934"><tr data-start="5487" data-end="5578"><td data-start="5487" data-end="5517" data-col-size="sm">GPT-3.5 fine-tuned</td><td data-start="5517" data-end="5530" data-col-size="sm">$20</td><td data-start="5530" data-end="5542" data-col-size="sm">100%</td><td data-start="5542" data-end="5557" data-col-size="sm">Good</td><td data-start="5557" data-end="5578" data-col-size="sm">Best for patterns</td></tr><tr data-start="5579" data-end="5669"><td data-start="5579" data-end="5609" data-col-size="sm">GPT-4o-mini fine-tuned</td><td data-start="5609" data-end="5622" data-col-size="sm">$3.50</td><td data-start="5622" data-end="5634" data-col-size="sm">100%</td><td data-start="5634" data-end="5649" data-col-size="sm">Better</td><td data-start="5649" data-end="5669" data-col-size="sm"><strong data-start="5651" data-end="5667">Best overall</strong></td></tr><tr data-start="5670" data-end="5760"><td data-start="5670" data-end="5700" data-col-size="sm">GPT-4.1-nano fine-tuned</td><td data-start="5700" data-end="5713" data-col-size="sm">$3.50</td><td data-start="5713" data-end="5725" data-col-size="sm">0%</td><td data-start="5725" data-end="5740" data-col-size="sm">Excellent</td><td data-start="5740" data-end="5760" data-col-size="sm">Not for patterns</td></tr><tr data-start="5761" data-end="5847"><td data-start="5761" data-end="5791" data-col-size="sm">GPT-4.1-nano + post-process</td><td data-start="5791" data-end="5804" data-col-size="sm">$3.50</td><td data-start="5804" data-end="5816" data-col-size="sm">100%*</td><td data-start="5816" data-end="5831" data-col-size="sm">Excellent</td><td data-start="5831" data-end="5847" data-col-size="sm">Best quality</td></tr><tr data-start="5848" data-end="5934"></tr></tbody></table>
<!--kg-card-end: html-->
<p>* With post-processing</p><hr><h2 id="key-takeaways">Key Takeaways</h2><figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2025/09/output.png" class="kg-image" alt="" loading="lazy" width="1453" height="1097" srcset="__GHOST_URL__/content/images/size/w600/2025/09/output.png 600w, __GHOST_URL__/content/images/size/w1000/2025/09/output.png 1000w, __GHOST_URL__/content/images/2025/09/output.png 1453w" sizes="(min-width: 720px) 720px"></figure><ul><li><strong>More advanced ‚â† better for every task</strong></li><li><strong>Always evaluate fine-tuned models thoroughly</strong></li><li><strong>Consider hybrid approaches</strong> (fine-tuning + post-processing)</li></ul><hr><h2 id="conclusion">Conclusion</h2><p>As models grow smarter, they develop stronger priors about ‚Äúcorrect‚Äù outputs. GPT-4.1-nano was so advanced it resisted learning what it saw as an <em>unnatural pattern</em>. The irony: it‚Äôs ‚Äútoo smart for its own good.‚Äù</p><p>üëâ The lesson: <strong>Pick models based on task, not just capabilities.</strong></p>